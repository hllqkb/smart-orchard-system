"""
æ™ºèƒ½æœå›­æ£€æµ‹ç³»ç»Ÿ - æŸ‘æ©˜æ£€æµ‹æ¨¡å—
"""

import streamlit as st
import cv2
import numpy as np
import time
import torch
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from ultralytics import YOLO
import tempfile
import os

from config.settings import MODEL_PATHS, DETECTION_CONFIG, CITRUS_CATEGORIES, MODEL_INFO
from config.database import db_manager

class CitrusDetector:
    """æŸ‘æ©˜æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.model = None
        self.model_path = MODEL_PATHS["yolo_citrus"]
        self.confidence_threshold = DETECTION_CONFIG["confidence_threshold"]
        self.iou_threshold = DETECTION_CONFIG["iou_threshold"]
        self.supported_formats = DETECTION_CONFIG["supported_formats"]
        self.max_file_size = DETECTION_CONFIG["max_file_size"]
        self.categories = CITRUS_CATEGORIES
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    @st.cache_resource
    def load_model(_self):
        """åŠ è½½YOLOæŸ‘æ©˜æ£€æµ‹æ¨¡å‹"""
        try:
            if _self.model_path and os.path.exists(_self.model_path):
                model = YOLO(_self.model_path)

                # æ‰“å°æ¨¡å‹ä¿¡æ¯ç”¨äºè°ƒè¯•
                print(f"æ¨¡å‹ç±»åˆ«åç§°: {model.names}")
                print(f"é…ç½®çš„ç±»åˆ«: {_self.categories}")

                return model
            else:
                st.warning("âš ï¸ æŸ‘æ©˜æ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„")
                return None
        except Exception as e:
            st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return None
    
    def detect_objects(self, image, confidence_threshold=None, iou_threshold=None):
        """æ£€æµ‹å›¾åƒä¸­çš„æŸ‘æ©˜"""
        if self.model is None:
            self.model = self.load_model()
            if self.model is None:
                return None, "æ¨¡å‹æœªåŠ è½½"
        
        try:
            # ä½¿ç”¨æŒ‡å®šçš„é˜ˆå€¼æˆ–é»˜è®¤å€¼
            conf = confidence_threshold if confidence_threshold is not None else self.confidence_threshold
            iou = iou_threshold if iou_threshold is not None else self.iou_threshold
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.perf_counter()
            
            # è¿›è¡Œæ£€æµ‹
            results = self.model(
                image,
                conf=conf,
                iou=iou,
                verbose=False
            )
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.perf_counter()
            inference_time = end_time - start_time
            
            return results[0], inference_time
            
        except Exception as e:
            return None, f"æ£€æµ‹å¤±è´¥: {str(e)}"
    
    def draw_detections(self, image, result, show_confidence=True, show_labels=True, show_boxes=True, line_width=2):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        if result.boxes is None or len(result.boxes) == 0:
            return np.array(image)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_array = np.array(image)
        
        # è·å–æ£€æµ‹ç»“æœ
        boxes = result.boxes.xyxy.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy().astype(int)
        confidences = result.boxes.conf.cpu().numpy()
        
        # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹æ¡†
        for box, cls, conf in zip(boxes, classes, confidences):
            x1, y1, x2, y2 = box.astype(int)
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            category_info = self.categories.get(cls, {"color": (128, 128, 128), "display": "æœªçŸ¥"})
            color = category_info["color"]
            
            if show_boxes:
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(img_array, (x1, y1), (x2, y2), color, line_width)
            
            if show_labels or show_confidence:
                # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
                label_parts = []
                if show_labels:
                    label_parts.append(category_info["display"])
                if show_confidence:
                    label_parts.append(f"{conf:.2f}")
                
                label = " ".join(label_parts)
                
                # è®¡ç®—æ–‡æœ¬å°ºå¯¸
                font_scale = 0.6
                font_thickness = 2
                text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]
                
                # æ–‡æœ¬ä½ç½®
                text_x = x1
                text_y = y1 - 10 if y1 - 10 > text_size[1] else y1 + text_size[1] + 10
                
                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                cv2.rectangle(
                    img_array,
                    (text_x, text_y - text_size[1] - 5),
                    (text_x + text_size[0] + 5, text_y + 5),
                    color,
                    -1
                )
                
                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(
                    img_array,
                    label,
                    (text_x + 2, text_y - 2),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    font_scale,
                    (255, 255, 255),
                    font_thickness,
                    cv2.LINE_AA
                )
        
        return img_array
    
    def analyze_detection_results(self, result):
        """åˆ†ææ£€æµ‹ç»“æœ"""
        if result.boxes is None or len(result.boxes) == 0:
            return {
                "total_count": 0,
                "category_counts": {},
                "confidences": [],
                "avg_confidence": 0.0,
                "max_confidence": 0.0,
                "detection_details": []
            }

        # è·å–æ£€æµ‹ç»“æœ
        boxes = result.boxes.xyxy.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy().astype(int)
        confidences = result.boxes.conf.cpu().numpy()

        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        category_counts = {}
        detection_details = []

        for i, (box, cls, conf) in enumerate(zip(boxes, classes, confidences)):
            # ç¡®ä¿ç±»åˆ«ç´¢å¼•æ­£ç¡®
            category_info = self.categories.get(cls, {"display": f"ç±»åˆ«{cls}"})
            category_name = category_info["display"]

            if category_name not in category_counts:
                category_counts[category_name] = 0
            category_counts[category_name] += 1

            # è¯¦ç»†ä¿¡æ¯ - è½¬æ¢æ‰€æœ‰numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
            detection_details.append({
                "åºå·": int(i + 1),
                "ç±»åˆ«": str(category_name),
                "ç½®ä¿¡åº¦": f"{float(conf):.2%}",
                "è¾¹ç•Œæ¡†": f"({int(box[0])}, {int(box[1])}, {int(box[2])}, {int(box[3])})",
                "é¢ç§¯": f"{int((box[2] - box[0]) * (box[3] - box[1]))}"
            })

        # è½¬æ¢æ‰€æœ‰numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ä»¥æ”¯æŒJSONåºåˆ—åŒ–
        return {
            "total_count": int(len(boxes)),
            "category_counts": category_counts,
            "confidences": [float(c) for c in confidences],
            "avg_confidence": float(np.mean(confidences)),
            "max_confidence": float(np.max(confidences)),
            "detection_details": detection_details
        }
    
    def save_detection_result(self, user_id, image_path, analysis_result, confidence_threshold, inference_time):
        """ä¿å­˜æ£€æµ‹ç»“æœåˆ°æ•°æ®åº“"""
        try:
            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            result_data = {
                "analysis": analysis_result,
                "inference_time": inference_time,
                "parameters": {
                    "confidence_threshold": confidence_threshold,
                    "iou_threshold": self.iou_threshold
                }
            }
            
            db_manager.save_detection_result(
                user_id=user_id,
                detection_type="citrus_detection",
                image_path=image_path,
                results=result_data,
                confidence_threshold=confidence_threshold,
                detection_count=analysis_result["total_count"]
            )
            
            return True
        except Exception as e:
            st.error(f"ä¿å­˜æ£€æµ‹ç»“æœå¤±è´¥: {str(e)}")
            return False
    
    def show_detection_interface(self, user_id):
        """æ˜¾ç¤ºæ£€æµ‹ç•Œé¢"""
        st.markdown("## ğŸŠ æŸ‘æ©˜æ™ºèƒ½æ£€æµ‹")

        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        if self.model is None:
            self.model = self.load_model()

        if self.model is not None:
            st.success("âœ… æŸ‘æ©˜æ£€æµ‹æ¨¡å‹å·²åŠ è½½ (YOLOv11s)")
        else:
            st.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

        # æ£€æµ‹å‚æ•°è®¾ç½®
        with st.sidebar:
            st.markdown("### âš™ï¸ æ£€æµ‹å‚æ•°")
            confidence_threshold = st.slider(
                "ç½®ä¿¡åº¦é˜ˆå€¼",
                min_value=0.1,
                max_value=1.0,
                value=self.confidence_threshold,
                step=0.05,
                help="åªæ˜¾ç¤ºç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼çš„æ£€æµ‹ç»“æœ"
            )
            
            iou_threshold = st.slider(
                "IoUé˜ˆå€¼",
                min_value=0.1,
                max_value=1.0,
                value=self.iou_threshold,
                step=0.05,
                help="éæå¤§å€¼æŠ‘åˆ¶çš„IoUé˜ˆå€¼"
            )
            
            # æ˜¾ç¤ºé€‰é¡¹
            st.markdown("### ğŸ¨ æ˜¾ç¤ºé€‰é¡¹")
            show_confidence = st.checkbox("æ˜¾ç¤ºç½®ä¿¡åº¦", value=True)
            show_labels = st.checkbox("æ˜¾ç¤ºæ ‡ç­¾", value=True)
            show_boxes = st.checkbox("æ˜¾ç¤ºè¾¹ç•Œæ¡†", value=True)
            line_width = st.slider("è¾¹ç•Œæ¡†çº¿æ¡å®½åº¦", min_value=1, max_value=5, value=2)
        
        # æ£€æµ‹æ¨¡å¼é€‰æ‹©
        detection_mode = st.radio(
            "é€‰æ‹©æ£€æµ‹æ¨¡å¼:",
            ["å•å¼ å›¾åƒæ£€æµ‹", "æ‰¹é‡å›¾åƒæ£€æµ‹"],
            horizontal=True
        )
        
        if detection_mode == "å•å¼ å›¾åƒæ£€æµ‹":
            self.show_single_image_detection(
                user_id, confidence_threshold, iou_threshold,
                show_confidence, show_labels, show_boxes, line_width
            )
        else:
            self.show_batch_image_detection(
                user_id, confidence_threshold, iou_threshold,
                show_confidence, show_labels, show_boxes, line_width
            )
    
    def show_single_image_detection(self, user_id, confidence_threshold, iou_threshold,
                                  show_confidence, show_labels, show_boxes, line_width):
        """æ˜¾ç¤ºå•å¼ å›¾åƒæ£€æµ‹ç•Œé¢"""
        st.markdown("### ğŸ–¼ï¸ å•å¼ å›¾åƒæ£€æµ‹")
        
        # å›¾åƒä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©è¦æ£€æµ‹çš„å›¾åƒ",
            type=self.supported_formats,
            help=f"æ”¯æŒæ ¼å¼: {', '.join(self.supported_formats).upper()}"
        )
        
        if uploaded_file is not None:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if uploaded_file.size > self.max_file_size:
                st.error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({self.max_file_size / (1024*1024):.1f}MB)")
                return
            
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            image = Image.open(uploaded_file)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸ“· åŸå§‹å›¾åƒ")
                st.image(image, caption="ä¸Šä¼ çš„å›¾åƒ", use_container_width=True)
            
            # æ£€æµ‹æŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹æ£€æµ‹", use_container_width=True):
                with st.spinner("ğŸ”„ æ­£åœ¨è¿›è¡Œæ£€æµ‹..."):
                    # è¿›è¡Œæ£€æµ‹
                    result, inference_time = self.detect_objects(image, confidence_threshold, iou_threshold)
                    
                    if result is not None and not isinstance(result, str):
                        with col2:
                            st.markdown("#### ğŸ¯ æ£€æµ‹ç»“æœ")
                            
                            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                            annotated_image = self.draw_detections(
                                image, result, show_confidence, show_labels, show_boxes, line_width
                            )
                            
                            # æ˜¾ç¤ºç»“æœå›¾åƒ
                            annotated_image_pil = Image.fromarray(annotated_image)
                            st.image(annotated_image_pil, caption="æ£€æµ‹ç»“æœ", use_container_width=True)
                        
                        # åˆ†æç»“æœ
                        analysis = self.analyze_detection_results(result)
                        
                        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                        self.show_detection_statistics(analysis, inference_time)
                        
                        # ä¿å­˜ç»“æœ
                        if self.save_detection_result(user_id, uploaded_file.name, analysis, confidence_threshold, inference_time):
                            st.success("âœ… æ£€æµ‹ç»“æœå·²ä¿å­˜")
                    
                    else:
                        st.error(f"æ£€æµ‹å¤±è´¥: {result if isinstance(result, str) else 'æœªçŸ¥é”™è¯¯'}")
        else:
            st.info("è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶å¼€å§‹æ£€æµ‹")
    
    def show_batch_image_detection(self, user_id, confidence_threshold, iou_threshold,
                                 show_confidence, show_labels, show_boxes, line_width):
        """æ˜¾ç¤ºæ‰¹é‡å›¾åƒæ£€æµ‹ç•Œé¢"""
        st.markdown("### ğŸ“ æ‰¹é‡å›¾åƒæ£€æµ‹")
        
        # æ‰¹é‡ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "é€‰æ‹©å¤šå¼ å›¾åƒè¿›è¡Œæ‰¹é‡æ£€æµ‹",
            type=self.supported_formats,
            accept_multiple_files=True,
            help="å¯ä»¥åŒæ—¶é€‰æ‹©å¤šå¼ å›¾åƒè¿›è¡Œæ‰¹é‡æ£€æµ‹"
        )
        
        if uploaded_files:
            st.success(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} å¼ å›¾åƒ")
            
            # æ‰¹é‡æ£€æµ‹æŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹", use_container_width=True):
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # å­˜å‚¨æ‰€æœ‰ç»“æœ
                all_results = []
                total_time = 0
                
                for i, uploaded_file in enumerate(uploaded_files):
                    # æ›´æ–°è¿›åº¦
                    progress = (i + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    if uploaded_file.size > self.max_file_size:
                        continue
                    
                    # å¤„ç†å•å¼ å›¾åƒ
                    image = Image.open(uploaded_file)
                    result, inference_time = self.detect_objects(image, confidence_threshold, iou_threshold)
                    
                    if result is not None and not isinstance(result, str):
                        total_time += inference_time
                        analysis = self.analyze_detection_results(result)
                        
                        all_results.append({
                            "æ–‡ä»¶å": uploaded_file.name,
                            "æ£€æµ‹æ•°é‡": analysis["total_count"],
                            "å¹³å‡ç½®ä¿¡åº¦": f"{analysis['avg_confidence']:.2%}",
                            "å¤„ç†æ—¶é—´": f"{inference_time:.3f}s",
                            "å›¾åƒ": image,
                            "ç»“æœ": result,
                            "åˆ†æ": analysis
                        })
                        
                        # ä¿å­˜ç»“æœ
                        self.save_detection_result(user_id, uploaded_file.name, analysis, confidence_threshold, inference_time)
                
                # å®Œæˆå¤„ç†
                progress_bar.progress(1.0)
                status_text.text("âœ… æ‰¹é‡æ£€æµ‹å®Œæˆ!")
                
                # æ˜¾ç¤ºæ‰¹é‡æ£€æµ‹ç»Ÿè®¡
                self.show_batch_statistics(all_results, total_time)
        else:
            st.info("è¯·é€‰æ‹©å›¾åƒæ–‡ä»¶è¿›è¡Œæ‰¹é‡æ£€æµ‹")
    
    def show_detection_statistics(self, analysis, inference_time):
        """æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        st.markdown("## ğŸ“ˆ æ£€æµ‹ç»Ÿè®¡")
        
        if analysis["total_count"] > 0:
            # åŸºæœ¬ç»Ÿè®¡
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ğŸ¯ æ£€æµ‹æ•°é‡", analysis["total_count"])
            
            with col2:
                st.metric("ğŸ“Š å¹³å‡ç½®ä¿¡åº¦", f"{analysis['avg_confidence']:.2%}")
            
            with col3:
                st.metric("ğŸ† æœ€é«˜ç½®ä¿¡åº¦", f"{analysis['max_confidence']:.2%}")
            
            with col4:
                st.metric("â±ï¸ æ£€æµ‹æ—¶é—´", f"{inference_time:.3f}s")
            
            # ç±»åˆ«åˆ†å¸ƒå›¾è¡¨
            if analysis["category_counts"]:
                st.markdown("### ğŸ“Š ç±»åˆ«åˆ†å¸ƒ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # é¥¼å›¾
                    fig_pie = px.pie(
                        values=list(analysis["category_counts"].values()),
                        names=list(analysis["category_counts"].keys()),
                        title="æ£€æµ‹ç±»åˆ«åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
                
                with col2:
                    # æŸ±çŠ¶å›¾
                    fig_bar = px.bar(
                        x=list(analysis["category_counts"].keys()),
                        y=list(analysis["category_counts"].values()),
                        title="å„ç±»åˆ«æ£€æµ‹æ•°é‡"
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
            
            # è¯¦ç»†æ£€æµ‹ç»“æœè¡¨æ ¼
            with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æ£€æµ‹ç»“æœ"):
                detection_df = pd.DataFrame(analysis["detection_details"])
                st.dataframe(detection_df, use_container_width=True)
        
        else:
            st.info("æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡ï¼Œè¯·å°è¯•é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–ä½¿ç”¨æ›´æ¸…æ™°çš„å›¾åƒ")
    
    def show_batch_statistics(self, all_results, total_time):
        """æ˜¾ç¤ºæ‰¹é‡æ£€æµ‹ç»Ÿè®¡"""
        st.markdown("## ğŸ“Š æ‰¹é‡æ£€æµ‹ç»Ÿè®¡")
        
        if all_results:
            col1, col2, col3, col4 = st.columns(4)
            
            total_detections = sum([r["æ£€æµ‹æ•°é‡"] for r in all_results])
            avg_time = total_time / len(all_results)
            successful_detections = len([r for r in all_results if r["æ£€æµ‹æ•°é‡"] > 0])
            
            with col1:
                st.metric("ğŸ“ å¤„ç†å›¾åƒ", len(all_results))
            
            with col2:
                st.metric("ğŸ¯ æ€»æ£€æµ‹æ•°", total_detections)
            
            with col3:
                st.metric("â±ï¸ å¹³å‡æ—¶é—´", f"{avg_time:.3f}s")
            
            with col4:
                success_rate = successful_detections / len(all_results) * 100
                st.metric("âœ… æˆåŠŸç‡", f"{success_rate:.1f}%")
            
            # è¯¦ç»†ç»“æœè¡¨æ ¼
            st.markdown("### ğŸ“‹ è¯¦ç»†ç»“æœ")
            results_df = pd.DataFrame([
                {
                    "æ–‡ä»¶å": r["æ–‡ä»¶å"],
                    "æ£€æµ‹æ•°é‡": r["æ£€æµ‹æ•°é‡"],
                    "å¹³å‡ç½®ä¿¡åº¦": r["å¹³å‡ç½®ä¿¡åº¦"],
                    "å¤„ç†æ—¶é—´": r["å¤„ç†æ—¶é—´"]
                } for r in all_results
            ])
            st.dataframe(results_df, use_container_width=True)

# å…¨å±€æŸ‘æ©˜æ£€æµ‹å™¨å®ä¾‹
citrus_detector = CitrusDetector()
